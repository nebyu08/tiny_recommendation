{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d170cb0-f477-4734-9fb0-3fd9f26f981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41642a91",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 7.708278,
     "end_time": "2024-07-31T08:17:49.974919",
     "exception": false,
     "start_time": "2024-07-31T08:17:42.266641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe3f5b",
   "metadata": {
    "papermill": {
     "duration": 0.01157,
     "end_time": "2024-07-31T08:17:49.998182",
     "exception": false,
     "start_time": "2024-07-31T08:17:49.986612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de5f632c",
   "metadata": {
    "papermill": {
     "duration": 8.74337,
     "end_time": "2024-07-31T08:17:58.753064",
     "exception": false,
     "start_time": "2024-07-31T08:17:50.009694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import dataset\n",
    "ds=pd.read_csv('C:/Users/nebiy/Documents/Dataset/datasets/Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7c3bcb1",
   "metadata": {
    "papermill": {
     "duration": 0.042471,
     "end_time": "2024-07-31T08:17:58.807558",
     "exception": false,
     "start_time": "2024-07-31T08:17:58.765087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c9f09",
   "metadata": {
    "papermill": {
     "duration": 0.01134,
     "end_time": "2024-07-31T08:17:58.830645",
     "exception": false,
     "start_time": "2024-07-31T08:17:58.819305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b690ff74",
   "metadata": {
    "papermill": {
     "duration": 0.377752,
     "end_time": "2024-07-31T08:17:59.220775",
     "exception": false,
     "start_time": "2024-07-31T08:17:58.843023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51a50e2f",
   "metadata": {
    "papermill": {
     "duration": 0.361146,
     "end_time": "2024-07-31T08:17:59.593853",
     "exception": false,
     "start_time": "2024-07-31T08:17:59.232707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               26\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "238c0c76",
   "metadata": {
    "papermill": {
     "duration": 0.421641,
     "end_time": "2024-07-31T08:18:00.028486",
     "exception": false,
     "start_time": "2024-07-31T08:17:59.606845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds=ds.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4ffbf44",
   "metadata": {
    "papermill": {
     "duration": 0.03114,
     "end_time": "2024-07-31T08:18:00.071896",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.040756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e9557c9",
   "metadata": {
    "papermill": {
     "duration": 0.02115,
     "end_time": "2024-07-31T08:18:00.105674",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.084524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ds[ds['UserId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d53b104d",
   "metadata": {
    "papermill": {
     "duration": 0.041994,
     "end_time": "2024-07-31T08:18:00.160182",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.118188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.drop(['ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Summary','Text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5aff2f55",
   "metadata": {
    "papermill": {
     "duration": 0.048516,
     "end_time": "2024-07-31T08:18:00.221127",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.172611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "1350345600    1143\n",
       "1322179200    1088\n",
       "1322438400    1070\n",
       "1346889600    1018\n",
       "1344211200     989\n",
       "              ... \n",
       "1095638400       1\n",
       "1102636800       1\n",
       "1080259200       1\n",
       "1087689600       1\n",
       "1069718400       1\n",
       "Name: count, Length: 3168, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "faf2b25c",
   "metadata": {
    "papermill": {
     "duration": 0.152684,
     "end_time": "2024-07-31T08:18:00.386372",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.233688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 568401 entries, 0 to 568453\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   Id         568401 non-null  int64 \n",
      " 1   ProductId  568401 non-null  object\n",
      " 2   UserId     568401 non-null  object\n",
      " 3   Score      568401 non-null  int64 \n",
      " 4   Time       568401 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 26.0+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f1db3-9035-46b3-ac5d-fb6d02b33f21",
   "metadata": {},
   "source": [
    "# Encoding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71cc3cfd-3596-44e3-83c4-1db12f3fd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_encoders={}\n",
    "columns=['ProductId','UserId']\n",
    "for col in columns:\n",
    "    le=LabelEncoder()\n",
    "    ds[col]=le.fit_transform(ds[col])\n",
    "    #storing the feature values and its encoded values\n",
    "    object_encoders[col]=le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f050de5",
   "metadata": {
    "papermill": {
     "duration": 0.01308,
     "end_time": "2024-07-31T08:18:00.412989",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.399909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets make more features:\n",
    "    * day of the week\n",
    "    * month\n",
    "    * time of the day(Hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f7820d2",
   "metadata": {
    "papermill": {
     "duration": 0.138275,
     "end_time": "2024-07-31T08:18:00.563937",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.425662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change the time stamp into datatime\n",
    "ds['Time']=pd.to_datetime(ds['Time'],unit='s',utc=True)\n",
    "ds['Time']=ds['Time'].dt.tz_convert('America/New_York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7848626f",
   "metadata": {
    "papermill": {
     "duration": 0.035731,
     "end_time": "2024-07-31T08:18:00.612410",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.576679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27619</td>\n",
       "      <td>188633</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-04-26 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>72383</td>\n",
       "      <td>25104</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-06 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15267</td>\n",
       "      <td>210468</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-08-17 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19718</td>\n",
       "      <td>152622</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-06-12 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>69007</td>\n",
       "      <td>57800</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-20 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ProductId  UserId  Score                      Time\n",
       "0   1      27619  188633      5 2011-04-26 20:00:00-04:00\n",
       "1   2      72383   25104      1 2012-09-06 20:00:00-04:00\n",
       "2   3      15267  210468      4 2008-08-17 20:00:00-04:00\n",
       "3   4      19718  152622      2 2011-06-12 20:00:00-04:00\n",
       "4   5      69007   57800      5 2012-10-20 20:00:00-04:00"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48c8fc73",
   "metadata": {
    "papermill": {
     "duration": 0.030039,
     "end_time": "2024-07-31T08:18:00.655529",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.625490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27619</td>\n",
       "      <td>188633</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-04-26 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>72383</td>\n",
       "      <td>25104</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-06 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15267</td>\n",
       "      <td>210468</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-08-17 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19718</td>\n",
       "      <td>152622</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-06-12 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>69007</td>\n",
       "      <td>57800</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-20 20:00:00-04:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ProductId  UserId  Score                      Time\n",
       "0   1      27619  188633      5 2011-04-26 20:00:00-04:00\n",
       "1   2      72383   25104      1 2012-09-06 20:00:00-04:00\n",
       "2   3      15267  210468      4 2008-08-17 20:00:00-04:00\n",
       "3   4      19718  152622      2 2011-06-12 20:00:00-04:00\n",
       "4   5      69007   57800      5 2012-10-20 20:00:00-04:00"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b98e5cf2",
   "metadata": {
    "papermill": {
     "duration": 0.617674,
     "end_time": "2024-07-31T08:18:01.286361",
     "exception": false,
     "start_time": "2024-07-31T08:18:00.668687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#year\n",
    "ds['year']=ds['Time'].dt.year\n",
    "#month\n",
    "ds['month']=ds['Time'].dt.month\n",
    "#week\n",
    "ds['day_of_week']=ds['Time'].dt.dayofweek\n",
    "#hour\n",
    "ds['hour']=ds['Time'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3372d28",
   "metadata": {
    "papermill": {
     "duration": 0.032374,
     "end_time": "2024-07-31T08:18:01.331995",
     "exception": false,
     "start_time": "2024-07-31T08:18:01.299621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27619</td>\n",
       "      <td>188633</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-04-26 20:00:00-04:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>72383</td>\n",
       "      <td>25104</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-06 20:00:00-04:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15267</td>\n",
       "      <td>210468</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-08-17 20:00:00-04:00</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19718</td>\n",
       "      <td>152622</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-06-12 20:00:00-04:00</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>69007</td>\n",
       "      <td>57800</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-20 20:00:00-04:00</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ProductId  UserId  Score                      Time  year  month  \\\n",
       "0   1      27619  188633      5 2011-04-26 20:00:00-04:00  2011      4   \n",
       "1   2      72383   25104      1 2012-09-06 20:00:00-04:00  2012      9   \n",
       "2   3      15267  210468      4 2008-08-17 20:00:00-04:00  2008      8   \n",
       "3   4      19718  152622      2 2011-06-12 20:00:00-04:00  2011      6   \n",
       "4   5      69007   57800      5 2012-10-20 20:00:00-04:00  2012     10   \n",
       "\n",
       "   day_of_week      hour  \n",
       "0            1  20:00:00  \n",
       "1            3  20:00:00  \n",
       "2            6  20:00:00  \n",
       "3            6  20:00:00  \n",
       "4            5  20:00:00  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1e462c4e",
   "metadata": {
    "papermill": {
     "duration": 0.214153,
     "end_time": "2024-07-31T08:18:01.559615",
     "exception": false,
     "start_time": "2024-07-31T08:18:01.345462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id             0\n",
       "ProductId      0\n",
       "UserId         0\n",
       "Score          0\n",
       "Time           0\n",
       "year           0\n",
       "month          0\n",
       "day_of_week    0\n",
       "hour           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a3e8159",
   "metadata": {
    "papermill": {
     "duration": 0.056283,
     "end_time": "2024-07-31T08:18:01.629484",
     "exception": false,
     "start_time": "2024-07-31T08:18:01.573201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#droping the time column\n",
    "clean_data=ds.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7b704d2",
   "metadata": {
    "papermill": {
     "duration": 0.073619,
     "end_time": "2024-07-31T08:18:01.716750",
     "exception": false,
     "start_time": "2024-07-31T08:18:01.643131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dropign the ID\n",
    "clean_data.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8dc77e6d",
   "metadata": {
    "papermill": {
     "duration": 0.213197,
     "end_time": "2024-07-31T08:18:01.943593",
     "exception": false,
     "start_time": "2024-07-31T08:18:01.730396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 568401 entries, 0 to 568453\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   ProductId    568401 non-null  int32 \n",
      " 1   UserId       568401 non-null  int32 \n",
      " 2   Score        568401 non-null  int64 \n",
      " 3   year         568401 non-null  int32 \n",
      " 4   month        568401 non-null  int32 \n",
      " 5   day_of_week  568401 non-null  int32 \n",
      " 6   hour         568401 non-null  object\n",
      "dtypes: int32(5), int64(1), object(1)\n",
      "memory usage: 23.9+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6de227fc",
   "metadata": {
    "papermill": {
     "duration": 0.466623,
     "end_time": "2024-07-31T08:18:02.424213",
     "exception": false,
     "start_time": "2024-07-31T08:18:01.957590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert the hour feature into int\n",
    "clean_data['hour']=clean_data['hour'].apply(lambda x:x.hour )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7bad1",
   "metadata": {
    "papermill": {
     "duration": 0.01349,
     "end_time": "2024-07-31T08:18:02.451882",
     "exception": false,
     "start_time": "2024-07-31T08:18:02.438392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# lets add another feature:\n",
    "        * Name of the feature is: recomended\n",
    "        * the feature if gonna be boolean\n",
    "        * we are gonna assign it True if its equal or greater than 3 : False other wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4aa6a8f",
   "metadata": {
    "papermill": {
     "duration": 0.024652,
     "end_time": "2024-07-31T08:18:02.490510",
     "exception": false,
     "start_time": "2024-07-31T08:18:02.465858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_data['Recomended']=clean_data['Score']>=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c0854cc",
   "metadata": {
    "papermill": {
     "duration": 0.025856,
     "end_time": "2024-07-31T08:18:02.530143",
     "exception": false,
     "start_time": "2024-07-31T08:18:02.504287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductId', 'UserId', 'Score', 'year', 'month', 'day_of_week', 'hour',\n",
       "       'Recomended'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c1f35-d859-44d6-b16f-9830f4088ded",
   "metadata": {},
   "source": [
    "## droping the 'Rate'---> Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc610759-7fd3-4ace-86bc-45f0e6c7be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.drop(['Score'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ff0f5-7e49-4443-9dd8-f0f2411be1f4",
   "metadata": {},
   "source": [
    "# mapping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1c8f965-eda1-4232-874b-6fb9bb33e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2012    198050\n",
       "2011    163536\n",
       "2010     86088\n",
       "2009     55403\n",
       "2008     34144\n",
       "2007     22333\n",
       "2006      6686\n",
       "2005      1344\n",
       "2004       560\n",
       "2003       133\n",
       "2002        73\n",
       "2000        32\n",
       "2001        13\n",
       "1999         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebcddec0-b3a2-4b7e-9446-ae916ec172fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_function_year(year):\n",
    "    return year-1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40bd15ee-fdf4-490a-9242-4c4e9df128c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clone=clean_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d087ce3-9dac-488e-bf7c-535febb028a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['year']=clean_data['year'].apply(mapping_function_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1553f9f-e855-445e-b843-5444c4a76c48",
   "metadata": {},
   "source": [
    "# mapping hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c6e93a0-1400-4c9d-a8bc-24362b0caf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_function_hour(hour):\n",
    "    return hour-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4bf149b7-d5be-4c1c-8226-db607a7427f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "20    382504\n",
       "19    185897\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['hour'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c410eb28-2cfe-4299-b3f8-01f7c476c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['hour']=clean_data['hour'].apply(mapping_function_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85e0ffc4-dbe7-4ce1-aa66-fa8505f2ba6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>Recomended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27619</td>\n",
       "      <td>188633</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72383</td>\n",
       "      <td>25104</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15267</td>\n",
       "      <td>210468</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19718</td>\n",
       "      <td>152622</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69007</td>\n",
       "      <td>57800</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductId  UserId  year  month  day_of_week  hour  Recomended\n",
       "0      27619  188633    12      4            1     1        True\n",
       "1      72383   25104    13      9            3     1       False\n",
       "2      15267  210468     9      8            6     1        True\n",
       "3      19718  152622    12      6            6     1       False\n",
       "4      69007   57800    13     10            5     1        True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b3c3258-0066-4de0-b4d6-3207dd7f66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler=MinMaxScaler()\n",
    "\n",
    "# columns_to_scale=['year','month','hour','day_of_week']\n",
    "# clean_data[columns_to_scale]=scaler.fit_transform(clean_data[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "627ff3ca-6907-4ce1-877c-f8eaa3bd826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets change the boolean into number\n",
    "clean_data['Recomended']=clean_data['Recomended'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b015648",
   "metadata": {
    "papermill": {
     "duration": 0.013438,
     "end_time": "2024-07-31T08:18:02.557604",
     "exception": false,
     "start_time": "2024-07-31T08:18:02.544166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8abb0f83",
   "metadata": {
    "papermill": {
     "duration": 0.43086,
     "end_time": "2024-07-31T08:18:03.003150",
     "exception": false,
     "start_time": "2024-07-31T08:18:02.572290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "train,test=train_test_split(\n",
    "    clean_data,\n",
    "    random_state=42,\n",
    "    test_size=0.2,\n",
    "    stratify=clean_data['Recomended']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aaa40b-beac-4322-9c53-61829c39a982",
   "metadata": {},
   "source": [
    "# lets check for data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "90104e61-7511-4fda-b6f2-20dfb309dc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clean_data['year'],edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "36b566ea-23a4-4730-a5ed-8a5edbc320ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clean_data['hour'],edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d7ec2",
   "metadata": {
    "papermill": {
     "duration": 0.013714,
     "end_time": "2024-07-31T08:18:03.030890",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.017176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# turn them into torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "acd10c7c-6648-472a-bdd0-37069efddb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ed412d1a-dde5-46f3-bf1a-7df209dba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=torch.tensor(90,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "674254ec",
   "metadata": {
    "papermill": {
     "duration": 0.026573,
     "end_time": "2024-07-31T08:18:03.071328",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.044755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.data=data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #element to extract\n",
    "        item=self.data.iloc[idx]\n",
    "        \n",
    "        return {\n",
    "            \"product_id\":torch.tensor([item['ProductId']],dtype=torch.long).to(device),\n",
    "            \"user_id\":torch.tensor([item['UserId']],dtype=torch.long).to(device) ,\n",
    "            \"year\":torch.tensor([item['year']],dtype=torch.long).to(device) ,\n",
    "            \"month\":torch.tensor([item['month']],dtype=torch.long).to(device) ,\n",
    "            \"day_of_week\":torch.tensor([item['day_of_week']],dtype=torch.long).to(device) ,\n",
    "            \"hour\":torch.tensor([item['hour']],dtype=torch.long).to(device) ,\n",
    "            \"recomended\":torch.tensor([item['Recomended']],dtype=torch.float).to(device)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3d9a7",
   "metadata": {
    "papermill": {
     "duration": 0.013483,
     "end_time": "2024-07-31T08:18:03.099038",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.085555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## loading the torch dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "d1d2dcd1",
   "metadata": {
    "papermill": {
     "duration": 0.022494,
     "end_time": "2024-07-31T08:18:03.135384",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.112890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainig dataset\n",
    "train_dataset=Mydataset(train)\n",
    "test_dataset=Mydataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7e0924bb",
   "metadata": {
    "papermill": {
     "duration": 0.023508,
     "end_time": "2024-07-31T08:18:03.172672",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.149164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Mydataset object at 0x000001F5AFEF9400>\n",
      "<__main__.Mydataset object at 0x000001F5AFEF9AF0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f5407",
   "metadata": {
    "papermill": {
     "duration": 0.013516,
     "end_time": "2024-07-31T08:18:03.200493",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.186977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# turning it into torch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "88c8a2b1",
   "metadata": {
    "papermill": {
     "duration": 0.025701,
     "end_time": "2024-07-31T08:18:03.240029",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.214328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#making the train dataloader\n",
    "train_dataloader=DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "#making test dataloader\n",
    "test_dataloader=DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "9e39715f-ed1f-4b99-82a4-319306faeaf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# acessing elements of the dataloader\n",
    "for batch in train_dataloader:\n",
    "    print(batch['product_id'].shape)\n",
    "    print(batch['user_id'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e16b4e-aa05-4321-95c9-c3e4570931c5",
   "metadata": {},
   "source": [
    "# model package importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "59a2329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/nebiy/Documents/recommendation_system/tiny_recommendation/jupyter_notes/trial.py')\n",
    "from trial import WideDeep,WD_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "fdddf7bf-f1d2-4eb8-97cc-423a3c966d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=WD_Config()\n",
    "config.num_product=clean_data['ProductId'].nunique()\n",
    "config.num_users=clean_data['UserId'].nunique() \n",
    "config.num_year=clean_data[\"year\"].nunique()\n",
    "config.num_time_day=clean_data[\"hour\"].nunique()\n",
    "config.num_month=clean_data['month'].nunique()+1   #since in this column it start from 1\n",
    "config.num_day_week=clean_data[\"day_of_week\"].nunique()\n",
    "config.embedding_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "b8092a9c-c4f8-4674-8baa-776351aaf271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WD_Config(num_product=74257, num_users=256042, num_day_week=7, num_month=13, num_time_day=2, num_feature=6, embedding_dim=100, num_year=14)\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "05459af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=WideDeep(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe015709-d785-4b0c-a387-52eed6d6f477",
   "metadata": {},
   "source": [
    "# setup the config of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a04b7939-6e3a-4bbc-82e9-2acb15949ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_of_week\n",
       "2    87051\n",
       "1    85986\n",
       "0    85850\n",
       "6    85360\n",
       "3    79679\n",
       "5    72791\n",
       "4    71684\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"day_of_week\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d3c6194e-d77b-48d7-b27b-e798e353a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.num_product=clean_data['ProductId'].nunique()+1\n",
    "# config.num_users=clean_data['UserId'].nunique() +1\n",
    "# config.num_year=clean_data[\"year\"].nunique()+1\n",
    "# config.num_time_day=clean_data[\"hour\"].nunique()+1\n",
    "# config.num_month=clean_data['month'].nunique()+1\n",
    "# config.num_day_week=clean_data[\"day_of_week\"].nunique()+1\n",
    "# config.embedding_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "fba89ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "efa3712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim=torch.optim.AdamW(model.parameters(),lr=0.01)  #the deep component\n",
    "loss_fn=torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78406d-eefe-49b5-9175-d242f594f928",
   "metadata": {},
   "source": [
    "# lets debug some stuff with data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "fe58e7ed-753b-4886-b33c-fbba9793e645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# lets access 10 elements from one batch\n",
    "for batch in train_dataloader:\n",
    "    product_id=batch[\"product_id\"]\n",
    "    user_id=batch[\"user_id\"]\n",
    "    year=batch[\"year\"]\n",
    "    month=batch[\"month\"]\n",
    "    day_of_week=batch[\"day_of_week\"]\n",
    "    hour=batch[\"hour\"]\n",
    "    recomended=batch[\"recomended\"]\n",
    "    \n",
    "    print(product_id.size(0))\n",
    "    print(user_id.shape)\n",
    "    print(year.shape)\n",
    "    print(recomended.shape)\n",
    "    print(month.shape)\n",
    "    print(year.shape)\n",
    "    print(day_of_week.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81634b8a",
   "metadata": {},
   "source": [
    "# train my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "c12b4fc4-6fab-4617-a067-d4e0a5283dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraxt one batch \n",
    "for batch in train_dataloader:\n",
    "    one_batch=batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "1310f62e-a771-47fb-95ea-6c40b3aee85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reco=batch['recomended']\n",
    "# print(reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "2bd98dc7",
   "metadata": {
    "papermill": {
     "duration": 0.013723,
     "end_time": "2024-07-31T08:18:03.268739",
     "exception": false,
     "start_time": "2024-07-31T08:18:03.255016",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "the loss is 18.75000762939453\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "model-pred:tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]], grad_fn=<ClampBackward1>)\n",
      "actual-val:tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "#lets start the training\n",
    "n_epoch=100\n",
    "for epoch in range(n_epoch):\n",
    "    #getting the shape right\n",
    "    product_id=one_batch['product_id']\n",
    "    user_id=one_batch['user_id']\n",
    "    year=one_batch['year']\n",
    "    month=one_batch['month']\n",
    "    day_of_week=one_batch['day_of_week']\n",
    "    hour=one_batch['hour']\n",
    "    recomended=one_batch['recomended']\n",
    "\n",
    "    #changing the value of the recomended\n",
    "    recomended=recomended.float()\n",
    "\n",
    "    #print some of the values\n",
    "    # print(product_id.shape)\n",
    "    # print(user_id.shape)\n",
    "    # print(year.shape)\n",
    "    # print(month.shape)\n",
    "    # print(day_of_week.shape)\n",
    "    # print(hour.shape)\n",
    "    \n",
    "    #feed forward model\n",
    "    model_pred=model(\n",
    "        product_id,\n",
    "        user_id,\n",
    "        year,\n",
    "        month,\n",
    "        day_of_week,\n",
    "        hour\n",
    "    )\n",
    "\n",
    "    #compare differnce between target and actual\n",
    "    #print(model_pred.shape)\n",
    "    #print(recomended.shape)\n",
    "    \n",
    "    #for numerical stability lets use\n",
    "    epsilon=1e-7\n",
    "    model_pred=torch.clamp(model_pred,min=epsilon,max=1-epsilon)\n",
    "\n",
    "    #check out the out put after each epoch\n",
    "    print(f\"model-pred:{model_pred}\")\n",
    "    print(f\"actual-val:{recomended}\")\n",
    "    \n",
    "    #calculate the loss\n",
    "    loss=loss_fn(recomended,model_pred)\n",
    "   \n",
    "    \n",
    "    #zero grad\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step() #update the gradient \n",
    "    \n",
    "    \n",
    "    #display the loss every 5 epoch\n",
    "    if(epoch%10==0):\n",
    "        print(f\"the loss is {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f01b29-3fcf-43ba-a1a3-97b732a77554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc58167-fc3f-4601-9b52-3c9c90bd8424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcc723-18f6-4c8b-9b60-8bb75dc2538a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5062ab8-9190-4e11-89db-d3a3e2d8e394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81f71c-ebd8-4b6d-9d5f-f71bb7c3ee49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58bcb6-5a27-4a08-9a4f-ebc6840b7086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2038205,
     "sourceId": 3380672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5468798,
     "sourceId": 9067293,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.610004,
   "end_time": "2024-07-31T08:18:04.735322",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-31T08:17:39.125318",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
